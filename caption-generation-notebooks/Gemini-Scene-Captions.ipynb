{"cells":[{"cell_type":"code","source":["!pip install -U google-generativeai\n"],"metadata":{"id":"co85PVAW66Ah","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763973082844,"user_tz":300,"elapsed":8553,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"3d7422df-97a3-4570-d9ea-09c6c7d5812d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n","Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import os\n","print(\"KEY PRESENT:\", \"GOOGLE_API_KEY\" in os.environ)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Slj7l4d87ooz","executionInfo":{"status":"ok","timestamp":1763973090631,"user_tz":300,"elapsed":7,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"3030375d-6d5f-4e3e-cd30-af0751c453e0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["KEY PRESENT: False\n"]}]},{"cell_type":"code","source":["# # Cell 1: Setup and Install\n","\n","!pip install -q google-generativeai pillow imageio imageio-ffmpeg decord tqdm datasets\n","import google.generativeai as genai, os, json, torch\n","\n","GEMINI_API_KEY = \"AIzaSyAmEQXt2uK_SZKQ6ghSk3ROoNE-s97jny0\" ## Insert here\n","genai.configure(api_key=GEMINI_API_KEY)\n"],"metadata":{"id":"wNh_9lxEylQ1","executionInfo":{"status":"ok","timestamp":1763973101850,"user_tz":300,"elapsed":9147,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","# List all available models\n","for m in genai.list_models():\n","    print(f\"Name: {m.name}, Supported Generation Methods: {m.supported_generation_methods}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LFgWJuejbCgy","executionInfo":{"status":"ok","timestamp":1763973104821,"user_tz":300,"elapsed":524,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"f3b426ba-010b-4a9f-9ada-25dcfb8fd7f5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: models/embedding-gecko-001, Supported Generation Methods: ['embedText', 'countTextTokens']\n","Name: models/gemini-2.5-pro-preview-03-25, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-pro-preview-05-06, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-pro-preview-06-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-pro, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n","Name: models/gemini-2.0-flash, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-001, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-exp-image-generation, Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n","Name: models/gemini-2.0-flash-lite-001, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-lite, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-lite-preview-02-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-lite-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-pro-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-pro-exp-02-05, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-exp-1206, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-thinking-exp-01-21, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-thinking-exp, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.0-flash-thinking-exp-1219, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-preview-tts, Supported Generation Methods: ['countTokens', 'generateContent']\n","Name: models/gemini-2.5-pro-preview-tts, Supported Generation Methods: ['countTokens', 'generateContent']\n","Name: models/learnlm-2.0-flash-experimental, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3-1b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3-4b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3-12b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3-27b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3n-e4b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemma-3n-e2b-it, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemini-flash-latest, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-flash-lite-latest, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-pro-latest, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-lite, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-image-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-image, Supported Generation Methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-preview-09-2025, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-2.5-flash-lite-preview-09-2025, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-3-pro-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n","Name: models/gemini-3-pro-image-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n","Name: models/nano-banana-pro-preview, Supported Generation Methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n","Name: models/gemini-robotics-er-1.5-preview, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/gemini-2.5-computer-use-preview-10-2025, Supported Generation Methods: ['generateContent', 'countTokens']\n","Name: models/embedding-001, Supported Generation Methods: ['embedContent']\n","Name: models/text-embedding-004, Supported Generation Methods: ['embedContent']\n","Name: models/gemini-embedding-exp-03-07, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n","Name: models/gemini-embedding-exp, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n","Name: models/gemini-embedding-001, Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n","Name: models/aqa, Supported Generation Methods: ['generateAnswer']\n","Name: models/imagen-4.0-generate-preview-06-06, Supported Generation Methods: ['predict']\n","Name: models/imagen-4.0-ultra-generate-preview-06-06, Supported Generation Methods: ['predict']\n","Name: models/imagen-4.0-generate-001, Supported Generation Methods: ['predict']\n","Name: models/imagen-4.0-ultra-generate-001, Supported Generation Methods: ['predict']\n","Name: models/imagen-4.0-fast-generate-001, Supported Generation Methods: ['predict']\n","Name: models/veo-2.0-generate-001, Supported Generation Methods: ['predictLongRunning']\n","Name: models/veo-3.0-generate-001, Supported Generation Methods: ['predictLongRunning']\n","Name: models/veo-3.0-fast-generate-001, Supported Generation Methods: ['predictLongRunning']\n","Name: models/veo-3.1-generate-preview, Supported Generation Methods: ['predictLongRunning']\n","Name: models/veo-3.1-fast-generate-preview, Supported Generation Methods: ['predictLongRunning']\n","Name: models/gemini-2.0-flash-live-001, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n","Name: models/gemini-live-2.5-flash-preview, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n","Name: models/gemini-2.5-flash-live-preview, Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n","Name: models/gemini-2.5-flash-native-audio-latest, Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n","Name: models/gemini-2.5-flash-native-audio-preview-09-2025, Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n"]}]},{"cell_type":"code","source":["model = genai.GenerativeModel(\"gemini-2.5-pro\")\n"],"metadata":{"id":"IxDHExPDDpqo","executionInfo":{"status":"ok","timestamp":1763973127597,"user_tz":300,"elapsed":9,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model.generate_content(\"hi\").text\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"id":"KVsT1mVS6zyb","executionInfo":{"status":"ok","timestamp":1763973135312,"user_tz":300,"elapsed":6690,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"1ec100d8-995a-4bd9-d57a-4dcb3c791ffe"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello! How can I help you today?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["!du -sh /content/camerabench\n"],"metadata":{"id":"mOvp7vWFFFPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968008023,"user_tz":300,"elapsed":104,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"4865168b-a63e-4d88-d5a2-f53a634ddaf6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["du: cannot access '/content/camerabench': No such file or directory\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pUgP8I4mxODR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968009300,"user_tz":300,"elapsed":14,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"76bf20d3-e8f0-4d06-9c33-08b26884e3a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Root: /content/camerabench\n","Videos: /content/camerabench/videos_gif_mp4\n","Outputs: /content/camerabench/outputs\n"]}],"source":["# --- Colab: Create folders ---\n","import os, json\n","\n","ROOT = \"/content/camerabench\"\n","VIDS = f\"{ROOT}/videos_gif_mp4\"\n","OUTS = f\"{ROOT}/outputs\"\n","\n","for p in (ROOT, VIDS, OUTS):\n","    os.makedirs(p, exist_ok=True)\n","\n","print(\"Root:\", ROOT)\n","print(\"Videos:\", VIDS)\n","print(\"Outputs:\", OUTS)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lXGcEtPZxPp_","executionInfo":{"status":"ok","timestamp":1763968011040,"user_tz":300,"elapsed":58,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"outputs":[],"source":["# --- PATCH: re-define GIF‚ÜíMP4 utils with even-dimension padding ---\n","import imageio, imageio.v3 as iio\n","import numpy as np, os, warnings\n","from typing import Tuple, List\n","from PIL import Image\n","from decord import VideoReader, cpu\n","\n","def to_rgb_frame(arr: np.ndarray) -> np.ndarray:\n","    # PIL-safe conversion path\n","    if isinstance(arr, Image.Image):\n","        if arr.mode in (\"RGBA\", \"LA\"):\n","            arr = arr.convert(\"RGBA\")\n","            bg = Image.new(\"RGBA\", arr.size, (0, 0, 0, 0))\n","            bg.alpha_composite(arr)\n","            arr = bg.convert(\"RGB\")\n","        else:\n","            arr = arr.convert(\"RGB\")\n","        return np.array(arr, dtype=np.uint8)\n","\n","    # NumPy path\n","    if arr.dtype != np.uint8:\n","        a = arr.astype(np.float32)\n","        a = np.clip(a, 0, 255)\n","        arr = a.astype(np.uint8)\n","\n","    if arr.ndim == 2:  # gray -> RGB\n","        arr = np.stack([arr, arr, arr], axis=-1)\n","\n","    if arr.shape[-1] == 4:  # RGBA -> RGB (alpha over black)\n","        rgb = arr[..., :3].astype(np.float32)\n","        alpha = (arr[..., 3:4].astype(np.float32) / 255.0)\n","        rgb = (rgb * alpha).astype(np.uint8)\n","        arr = rgb\n","\n","    if arr.shape[-1] != 3:\n","        first = arr[..., 0]\n","        arr = np.stack([first, first, first], axis=-1).astype(np.uint8)\n","\n","    return arr\n","\n","def _ensure_same_size(frames: List[np.ndarray]) -> Tuple[List[np.ndarray], Tuple[int, int]]:\n","    \"\"\"Resize all frames to the first frame's WxH (consistent encoder input).\"\"\"\n","    if not frames:\n","        return frames, (0, 0)\n","    h, w = frames[0].shape[:2]\n","    out = []\n","    for f in frames:\n","        if f.shape[0] != h or f.shape[1] != w:\n","            pil = Image.fromarray(f)\n","            pil = pil.resize((w, h), resample=Image.Resampling.BILINEAR)\n","            f = np.array(pil, dtype=np.uint8)\n","        out.append(f)\n","    return out, (h, w)\n","\n","def _pad_to_even(frames: List[np.ndarray]) -> Tuple[List[np.ndarray], Tuple[int, int]]:\n","    \"\"\"Pad frames on the right/bottom by 1 pixel if width or height is odd (needed for yuv420p).\"\"\"\n","    if not frames:\n","        return frames, (0, 0)\n","    h, w = frames[0].shape[:2]\n","    pad_h = h % 2\n","    pad_w = w % 2\n","    if pad_h == 0 and pad_w == 0:\n","        return frames, (h, w)\n","\n","    H, W = h + pad_h, w + pad_w\n","    out = []\n","    for f in frames:\n","        canvas = np.zeros((H, W, 3), dtype=np.uint8)\n","        canvas[:h, :w, :] = f\n","        out.append(canvas)\n","    return out, (H, W)\n","\n","def decord_ok(path: str) -> bool:\n","    try:\n","        if not (os.path.exists(path) and os.path.getsize(path) > 0):\n","            return False\n","        vr = VideoReader(path, ctx=cpu(0))\n","        if len(vr) < 1:\n","            return False\n","        _ = vr[0]\n","        return True\n","    except Exception:\n","        return False\n","\n","def convert_gif_to_mp4(gif_path: str, mp4_path: str, fps: float = 8.0) -> bool:\n","    \"\"\"\n","    Robust GIF‚ÜíMP4:\n","      - normalize to RGB\n","      - force consistent WxH\n","      - **pad to even dims** for yuv420p\n","      - macro_block_size=1 to avoid implicit resizing\n","    \"\"\"\n","    try:\n","        frames = []\n","        with imageio.get_reader(gif_path) as reader:\n","            for frame in reader:\n","                frames.append(to_rgb_frame(frame))\n","        if not frames:\n","            warnings.warn(f\"No frames decoded from GIF: {gif_path}\")\n","            return False\n","\n","        frames, _ = _ensure_same_size(frames)\n","        frames, _ = _pad_to_even(frames)  # <-- critical fix for yuv420p\n","\n","        imageio.mimsave(\n","            mp4_path,\n","            frames,\n","            fps=fps,\n","            macro_block_size=1,\n","            codec=\"libx264\",\n","            format=\"FFMPEG\",\n","            ffmpeg_params=[\"-pix_fmt\", \"yuv420p\", \"-movflags\", \"+faststart\"],\n","        )\n","        return decord_ok(mp4_path)\n","    except Exception as e:\n","        warnings.warn(\n","            f\"GIF‚ÜíMP4 failed for {gif_path} -> {mp4_path}: {e}\\n\\n\"\n","            \"Tip: this is often due to odd frame sizes with yuv420p; padding to even dims usually fixes it.\"\n","        )\n","        return False"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"PQSc5v-SxQ_n","colab":{"base_uri":"https://localhost:8080/","height":662,"referenced_widgets":["7c4ada1e421c4c84b83f248802bff7c2","3fb51345f5f64dc7bead1d0b2cc36598","d3f4966049d64d7a905e0cb7451e1b3c","9fdb679e9c484e0996e09f6386cfb9d6","35ad0208b523411dad135fcdae542edf","37e0225c262d49f29854e64eb049a32a","42e340adff754d9cac54782f2a6eb64d","5900828a578245cf8478eb25a741f48d","a90f914b399b4632a41f656c12701197","17fdaf5b0e9142b780d5958ee96a342e","db6182df546747d889baf637514975cf","98f8247980054434972fb57ba437554a","319f757c1ac14bfa9329d2eef1633f5a","13c19467da4c44399800200fb6ca328b","70174eaab16d41f5874bbc74f8a5a97c","cbdd83f9ba9f44d48cd68ab8dbb72230","757190464a554e61b6874ded4b684227","606ed4ef49b74c33badfb39beef81a23","d7373bde21c64975ac413e82e0dbf3d5","1c7dbd022b7f42dbb9099700194e2a72","5903cb88278244cdb4d7d863c7c43dae","6ca6183e41f14be9a657666d2b78d736","8f1daeded20e4b219bd7088d57735412","593fdc39199a43dc8c74b819e687d4b5","beb91707559b472a82812da5026318e5","98b20c950f5147298ea60615642d3d3e","90a38217e5fc4d138bac0bb94be5fd9f","41f44a827b95469c9493d3203cf524c9","e447cefb8d5540d7b8fbba01dba93d5e","c00265b729fd45c38dfecb90078f4ac5","2a33ae91c8514d79baa4e45778d62db0","2fca1618a07f4bd0bd1bbb99edf11674","43f0110654884c5cb4f85510cf13057c"]},"executionInfo":{"status":"ok","timestamp":1763969953376,"user_tz":300,"elapsed":1938672,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"b463a6e5-da1a-461f-fb35-9dc788e4e9a3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4ada1e421c4c84b83f248802bff7c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test.jsonl: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f8247980054434972fb57ba437554a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1071 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f1daeded20e4b219bd7088d57735412"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rBuilding GIF‚ÜíMP4 manifest:   0%|          | 0/1071 [00:00<?, ?it/s]/tmp/ipython-input-3367234834.py:31: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n","  alpha = (arr[..., 3:4].astype(np.float32) / 255.0)\n","/tmp/ipython-input-3367234834.py:32: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n","  rgb = (rgb * alpha).astype(np.uint8)\n","Building GIF‚ÜíMP4 manifest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1071/1071 [32:13<00:00,  1.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Saved manifest: /content/camerabench/outputs/gif2mp4_manifest.json\n","Total items: 1071\n","Readable MP4s: 1071\n","\n","Sample manifest entry:\n","{\n","  \"row_idx\": 0,\n","  \"rel_path\": \"videos/-2uIa-XMJC0.5.3.mp4\",\n","  \"gif_url\": \"https://huggingface.co/datasets/syCen/CameraBench/resolve/main/videos_gif/-2uIa-XMJC0.5.3.gif\",\n","  \"local_gif\": \"/content/camerabench/videos_gif_mp4/3e1afda20f104270_-2uIa-XMJC0.5.3.gif\",\n","  \"local_mp4\": \"/content/camerabench/videos_gif_mp4/3e1afda20f104270_-2uIa-XMJC0.5.3.mp4\",\n","  \"status\": \"ok\"\n","}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# --- Colab: Load dataset & build manifest (download GIFs, convert to MP4) ---\n","import os, json, time, hashlib, requests\n","from datasets import load_dataset\n","from tqdm import tqdm\n","\n","MANIFEST_PATH = f\"{OUTS}/gif2mp4_manifest.json\"\n","\n","# Load split=\"test\"\n","ds = load_dataset(\"syCen/CameraBench\", split=\"test\")\n","\n","def safe_filename(url: str) -> str:\n","    \"\"\"Make a deterministic, safe base name from URL.\"\"\"\n","    h = hashlib.md5(url.encode(\"utf-8\")).hexdigest()[:16]\n","    base = os.path.basename(url).split(\"?\")[0]\n","    return f\"{h}_{base}\"\n","\n","def download_gif(url: str, out_path: str, timeout=20, retries=3) -> bool:\n","    for i in range(retries):\n","        try:\n","            r = requests.get(url, stream=True, timeout=timeout)\n","            if r.status_code == 200:\n","                with open(out_path, \"wb\") as f:\n","                    for chunk in r.iter_content(chunk_size=1024 * 256):\n","                        if chunk:\n","                            f.write(chunk)\n","                return os.path.exists(out_path) and os.path.getsize(out_path) > 0\n","        except Exception:\n","            time.sleep(1.0 * (i + 1))\n","    return False\n","\n","manifest = []\n","for idx, row in enumerate(tqdm(ds, desc=\"Building GIF‚ÜíMP4 manifest\")):\n","    gif_url = row.get(\"video\", None) or row.get(\"Video\", None)\n","    rel_path = row.get(\"path\", None)  # relative mp4 path/id in dataset metadata\n","    if not gif_url:\n","        continue\n","\n","    gif_name = safe_filename(gif_url)\n","    local_gif = os.path.join(VIDS, gif_name if gif_name.lower().endswith(\".gif\") else gif_name + \".gif\")\n","    local_mp4 = os.path.splitext(local_gif)[0] + \".mp4\"\n","\n","    # Download if not present\n","    if not os.path.exists(local_gif):\n","        ok = download_gif(gif_url, local_gif)\n","        if not ok:\n","            # Skip adding broken downloads; entry records failure state\n","            manifest.append({\n","                \"row_idx\": idx, \"rel_path\": rel_path, \"gif_url\": gif_url,\n","                \"local_gif\": local_gif, \"local_mp4\": local_mp4, \"status\": \"gif_download_failed\"\n","            })\n","            continue\n","\n","    # Convert to MP4 if needed\n","    if not os.path.exists(local_mp4):\n","        _ = convert_gif_to_mp4(local_gif, local_mp4, fps=8.0)\n","\n","    status = \"ok\" if decord_ok(local_mp4) else \"mp4_unreadable\"\n","    manifest.append({\n","        \"row_idx\": idx,\n","        \"rel_path\": rel_path,\n","        \"gif_url\": gif_url,\n","        \"local_gif\": local_gif,\n","        \"local_mp4\": local_mp4,\n","        \"status\": status,\n","    })\n","\n","# Save manifest\n","with open(MANIFEST_PATH, \"w\") as f:\n","    json.dump(manifest, f, indent=2)\n","\n","print(f\"Saved manifest: {MANIFEST_PATH}\")\n","print(\"Total items:\", len(manifest))\n","print(\"Readable MP4s:\", sum(1 for m in manifest if m[\"status\"] == \"ok\"))\n","print(\"\\nSample manifest entry:\")\n","print(json.dumps(next((m for m in manifest if m[\"status\"] == \"ok\"), manifest[0] if manifest else {}), indent=2))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XEurAn46xUNz","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1763973226996,"user_tz":300,"elapsed":80984,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"ad67efca-3adc-4c5d-bb9a-4258fd2516a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing on 5 videos\n","\n","üé• 3e1afda20f104270_-2uIa-XMJC0.5.3.mp4\n","‚è±Ô∏è 10.48s | A detailed description of the video scenes is as follows:\n","\n","**00:00 - 00:02**\n","The video opens with a high-angle shot looking down at a person dressed in all-white athletic wear, including a beanie, standing on a skateboard. They are positioned on a narrow ledge high up on a modern, dark building with large glass panels. In a swift, daring move, the person pushes off the ledge and drops down the side of the structure, riding their skateboard vertically for a moment before landing on another surface below.\n","\n","**00:02 - 00:05**\n","The camera angle switches to a dramatic, top-down, bird's-eye view. The person is now smoothly skateboarding across a long, transparent glass bridge or walkway, suspended high in the air. Below the clear glass, the ground and some foliage are visible far below, creating a dizzying sense of height. As the person continues to ride forward, the camera slowly pulls upward, emphasizing the vastness of the structure and the isolation of the lone figure against the cool, dark, bluish-green tones of the night.\n","\n","üé• d9faf33e350a923c_0TqQje61Hoo.3.1.mp4\n","‚è±Ô∏è 10.55s | A medium shot captures a young woman standing outdoors in a lush, wooded environment. A large, rustic log cabin with a wooden porch is visible behind her.\n","\n","The woman, who appears to be in her late teens or early twenties, has her light brown, curly hair pulled back. She is wearing a white tube top, an open, oversized black zip-up hoodie, and light-colored pants.\n","\n","Initially, she looks up and to the side with an expression of pleasant surprise or awe. As the clip progresses, she lifts her face completely towards the sky, closing her eyes and smiling gently, as if she is peacefully soaking in the natural atmosphere and scenery around her. The lighting is soft and natural, enhancing the serene and appreciative mood of the scene.\n","\n","üé• 0ab6b40c0b725ae6_0BmANHSUbJg.3.5.mp4\n","‚è±Ô∏è 16.92s | This short video clip presents a single, dramatic, high-angle shot of a plane crash aftermath at night.\n","\n","The scene is set on a dark, wet tarmac, likely at an airport or an industrial airbase. The ground is reflective, suggesting recent rain or firefighting efforts. The area is illuminated by bright, cold-toned floodlights, which cast long shadows and create a stark, cinematic feel.\n","\n","The central focus is a massive airplane that has crashed directly into a large hangar. The tail and rear section of the silver-colored aircraft are mostly intact and visible outside the building. A stylized dark-colored wing or bird logo is prominent on the plane's tail fin.\n","\n","The front of the plane has completely breached the hangar, causing catastrophic damage to both the aircraft and the structure. The hangar's large metal doors are crumpled, twisted, and torn apart, bent inwards from the force of the impact. Bright, warm light from inside the hangar spills out through the gaping hole.\n","\n","Thick smoke or steam billows from the wreckage where the plane meets the building, suggesting heat and ongoing danger. Debris is scattered extensively around the crash site, particularly to the left, where mangled pieces of metal, possibly from the plane's wing or cargo containers, lie in a heap.\n","\n","In the background to the right, a few white service or emergency vehicles are parked near the undamaged section of the hangar. The camera slowly zooms out or pulls back, gradually revealing the full scale of the devastation. The overall atmosphere is one of intense destruction and chaos.\n","\n","üé• aebc1b41601251b3_4847.13.4.mp4\n","‚è±Ô∏è 18.40s | This is a static, medium close-up shot, filmed in a sepia tone that gives it the quality of an old photograph or silent film.\n","\n","On the right side of the frame, a woman is seen in profile, gazing intently into a round mirror. She has dark, styled hair and is wearing a light-colored, textured coat with a high collar over a white shirt. A small, light-colored earring is visible.\n","\n","The mirror, on the left, is encased in an ornate, dark, intricately carved wooden frame and sits on a stand. The woman's reflection is visible within it, though her face is cast in deep shadow, creating a somber and mysterious counter-image.\n","\n","In her hand, she holds a small, metallic statuette of a seated Buddha figure. She slowly raises the statuette, holding it up as she continues to look at her reflection. The background features a wall with a delicate, painted pattern of branches and possibly flowers, suggesting an elegant interior setting. The overall mood is quiet, contemplative, and introspective.\n","\n","üé• 7104c32b794003a9_4080.2.3.mp4\n","‚è±Ô∏è 24.57s | Based on the short video clip, here is a detailed description of the scenes:\n","\n","**Scene at 00:00 - 00:01**\n","\n","The scene is an intense, chaotic, low-angle tracking shot that captures the legs and feet of a group of people running frantically through a wooded area. The camera is positioned at ground level, moving along with the runners, which creates a disorienting and immersive sense of urgency and panic.\n","\n","The ground is covered in dirt, dry leaves, and pine needles, indicating a forest setting. In the background, the out-of-focus trunks of trees and dappled sunlight are visible.\n","\n","The focus is on the churning legs and pounding feet. We see several individuals in motion. One person is wearing blue pants or jeans, and another is wearing a pair of distinctive, bulky, tan-colored boots that appear to be made of suede or a similar soft material. Other legs in lighter-colored pants and what look like sneakers flash by. The rapid movement and the shaky camera work result in significant motion blur, emphasizing the speed and chaos of the moment. The overall atmosphere is one of flight, a desperate chase, or an escape.\n","\n","‚úÖ Sanity test complete.\n"]}],"source":["# --- Cell 6: Sanity test using Gemini ---\n","import pathlib, json, os, time\n","\n","ROOT = \"/content/camerabench\"\n","MANIFEST_PATH = f\"{ROOT}/outputs/gif2mp4_manifest.json\"\n","\n","# Load manifest\n","with open(MANIFEST_PATH, \"r\") as f:\n","    manifest = json.load(f)\n","\n","test_items = [m for m in manifest if m[\"status\"] == \"ok\"][:5]\n","print(f\"Testing on {len(test_items)} videos\\n\")\n","\n","# Helper\n","def generate_caption_for_path(video_path: str, prompt=None) -> str:\n","    prompt = prompt or \"Describe scenes in detail.\"\n","    video_bytes = pathlib.Path(video_path).read_bytes()\n","    response = model.generate_content(\n","        [\n","            {\n","                \"role\": \"user\",\n","                \"parts\": [\n","                    {\"mime_type\": \"video/mp4\", \"data\": video_bytes},\n","                    prompt,\n","                ],\n","            }\n","        ],\n","        request_options={\"timeout\": 180},\n","    )\n","    return (response.text or \"\").strip()\n","\n","# Run a few tests\n","for m in test_items:\n","    vpath = m[\"local_mp4\"]\n","    print(f\"üé• {os.path.basename(vpath)}\")\n","    t0 = time.time()\n","    try:\n","        cap = generate_caption_for_path(vpath)\n","        print(f\"‚è±Ô∏è {time.time() - t0:.2f}s | {cap}\\n\")\n","    except Exception as e:\n","        print(f\"‚ùå Error on {vpath}: {e}\\n\")\n","\n","print(\"‚úÖ Sanity test complete.\")\n"]},{"cell_type":"code","source":["try:\n","    r = model.generate_content(\"Say 'Gemini is working.'\")\n","    print(\"RESPONSE:\", r.text)\n","except Exception as e:\n","    print(\"‚ùå TEXT TEST FAILED:\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"QSZjmMBx6Ndn","executionInfo":{"status":"error","timestamp":1763971891467,"user_tz":300,"elapsed":51294,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"d9adc53a-9da0-4717-e251-0f45554a6247"},"execution_count":31,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1574689785.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Say 'Gemini is working.'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RESPONSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ùå TEXT TEST FAILED:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             response = GenerativeServiceRestTransport._GenerateContent._get_response(\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             response = getattr(session, method)(\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    538\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vmtMXRw6IDJ","executionInfo":{"status":"ok","timestamp":1763971729152,"user_tz":300,"elapsed":26,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"b679391e-3aeb-40cf-d282-ccf1bcbbcc34"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["genai.GenerativeModel(\n","    model_name='models/gemini-2.5-pro',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n","    cached_content=None\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_gif.jsonl\" \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_scene+motion_backup.jsonl\"\n"],"metadata":{"id":"Xf43QSL_WE1D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","JSONL_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_motiononly.jsonl\"\n","\n","done = []\n","with open(JSONL_PATH, \"r\") as f:\n","    for line in f:\n","        try:\n","            rec = json.loads(line.strip())\n","            done.append(rec)\n","        except Exception:\n","            continue\n","\n","print(f\"‚úÖ Total completed videos: {len(done)}\")\n","print(\"üîπ Example entries:\")\n","for r in done[:5]:\n","    print(f\"row_idx={r['row_idx']}, caption={r['caption_generated'][:60]}...\")\n"],"metadata":{"id":"4KPbY_O45Pr9","colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"status":"error","timestamp":1763970265358,"user_tz":300,"elapsed":20,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"ef4e9e28-7127-48a4-eb5a-2ab93adac228"},"execution_count":12,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_motiononly.jsonl'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2990555068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSONL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_motiononly.jsonl'"]}]},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","import google.generativeai as genai\n","# genai.configure(api_key=\"YOUR_API_KEY\")   # if needed\n","model = genai.GenerativeModel(\"gemini-2.5-pro\")\n"],"metadata":{"id":"xS8Owvv96Qx1","colab":{"base_uri":"https://localhost:8080/","height":458},"executionInfo":{"status":"error","timestamp":1763970294860,"user_tz":300,"elapsed":8713,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"5e52cf56-93f0-4d75-b159-6e70abe1eb29"},"execution_count":13,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1278121600.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# genai.configure(api_key=\"YOUR_API_KEY\")   # if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["print(\"Copying locally for fast read...\")\n","!cp \"$JSONL_PATH\" /content/tmp_motion.jsonl\n","\n","done = set()\n","with open(\"/content/tmp_motion.jsonl\", \"r\") as f:\n","    for line in f:\n","        try:\n","            rec = json.loads(line)\n","            done.add(int(rec[\"row_idx\"]))\n","        except Exception:\n","            continue"],"metadata":{"id":"9l61tNVKCtrK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"‚úÖ Loaded {len(done)} entries.\")\n"],"metadata":{"id":"buLKLNzACwhx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_remaining"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1KQPszi5F9U","executionInfo":{"status":"ok","timestamp":1763971461976,"user_tz":300,"elapsed":22,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"beeb0593-00e9-4bca-ce42-3c2023b027fc"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1066"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# --- Cell 7: Chunked captioning with Gemini 2.5 Pro (camera motion only) ---\n","from google.colab import drive\n","from tqdm import tqdm\n","from datasets import load_dataset\n","import os, json, time, pathlib\n","\n","drive.mount('/content/drive')\n","\n","ROOT = \"/content/camerabench\"\n","OUTS = f\"{ROOT}/outputs\"\n","MANIFEST_PATH = f\"{OUTS}/gif2mp4_manifest.json\"\n","DRIVE_FOLDER = \"/content/drive/MyDrive/Deep Learning Fall 2025/Scene\"\n","JSONL_PATH = f\"{DRIVE_FOLDER}/motion_captions_gemini_scene.jsonl\"\n","\n","os.makedirs(DRIVE_FOLDER, exist_ok=True)\n","\n","## MOVE IT LOWER\n","# VIDEOS_PER_CHUNK = 3\n","# VIDEOS_PER_CHUNK = total_remaining\n","\n","print(\"Loading manifest and dataset...\")\n","with open(MANIFEST_PATH, \"r\") as f:\n","    manifest = json.load(f)\n","ds = load_dataset(\"syCen/CameraBench\", split=\"test\")\n","\n","# --- Fast local copy of progress file ---\n","done = set()\n","if os.path.exists(JSONL_PATH):\n","    print(\"Found existing progress file! Copying locally for fast read...\")\n","    LOCAL_JSONL = \"/content/temp_scene.jsonl\"\n","    !cp \"$JSONL_PATH\" \"$LOCAL_JSONL\"\n","\n","    with open(LOCAL_JSONL, \"r\") as f:\n","        for line in tqdm(f, desc=\"Loading completed entries\"):\n","            try:\n","                rec = json.loads(line.strip())\n","                done.add(int(rec[\"row_idx\"]))\n","            except Exception:\n","                continue\n","\n","processable = [m for m in manifest if m.get(\"status\") == \"ok\" and int(m[\"row_idx\"]) not in done]\n","\n","total_done = len(done)\n","total_remaining = len(processable)\n","total_videos = len([m for m in manifest if m.get(\"status\") == \"ok\"])\n","\n","# Code for VIDEOS PER CHUNK:\n","VIDEOS_PER_CHUNK = total_remaining\n","\n","\n","print(f\"\\n{'='*70}\")\n","print(f\"CAPTIONING STATUS (Google Drive)\")\n","print(f\"{'='*70}\")\n","print(f\"‚úÖ Already completed: {total_done} videos\")\n","print(f\"üìù Remaining: {total_remaining} videos\")\n","print(f\"üéØ Total readable videos: {total_videos}\")\n","print(f\"\\n‚ñ∂Ô∏è  This run will process: {min(VIDEOS_PER_CHUNK, total_remaining)} videos\")\n","print(f\"üíæ Progress file: {JSONL_PATH}\")\n","print(f\"{'='*70}\\n\")\n","\n","def caption_video_gemini(video_path: str, prompt=None) -> str:\n","    \"\"\"Generate a caption using Gemini 2.5 Pro (scnee only).\"\"\"\n","    prompt = prompt or \"Describe scenes in detail.\"\n","\n","    try:\n","        video_bytes = pathlib.Path(video_path).read_bytes()\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Could not read {video_path}: {e}\")\n","        return \"\"\n","\n","    try:\n","        response = model.generate_content(\n","            [\n","                {\n","                    \"role\": \"user\",\n","                    \"parts\": [\n","                        {\"mime_type\": \"video/mp4\", \"data\": video_bytes},\n","                        prompt,\n","                    ],\n","                }\n","            ],\n","            request_options={\"timeout\": 180},\n","        )\n","        return (response.text or \"\").strip()\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Error processing {os.path.basename(video_path)}: {e}\")\n","        return \"\"\n","\n","# --- Process chunk ---\n","if total_remaining == 0:\n","    print(\"üéâ All videos already captioned! Run Cell 9 to export to Excel.\")\n","else:\n","    chunk_to_process = processable[:VIDEOS_PER_CHUNK]\n","    ok_cnt, skip_cnt = 0, 0\n","\n","    with open(JSONL_PATH, \"a\") as jf:\n","        for m in tqdm(chunk_to_process, desc=f\"Captioning (chunk of {len(chunk_to_process)})\"):\n","            idx = int(m[\"row_idx\"])\n","            if idx in done:\n","                tqdm.write(f\"‚è≠Ô∏è Skipping already-completed video {idx}\")\n","                continue\n","\n","            vpath = m[\"local_mp4\"]\n","            try:\n","                start = time.time()\n","                cap = caption_video_gemini(vpath)\n","                duration = time.time() - start\n","                if not cap:\n","                    skip_cnt += 1\n","                    continue\n","\n","                row = ds[idx]\n","                rec = {\n","                    \"row_idx\": idx,\n","                    \"id_or_video_path\": row.get(\"path\"),\n","                    \"video_link\": m.get(\"gif_url\"),\n","                    \"local_mp4\": vpath,\n","                    \"caption_generated\": cap,\n","                    \"labels\": row.get(\"labels\"),\n","                    \"human_motion_caption\": row.get(\"caption\"),\n","                    \"model\": \"models/gemini-2.5-pro\",\n","                    \"runtime_seconds\": round(duration, 2),\n","                    \"source\": \"gif_preview_converted_to_mp4\",\n","                    \"task\": \"scene_baseline\"\n","                }\n","\n","                jf.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","                # jf.flush()\n","                if ok_cnt % 10 == 0:\n","                    jf.flush()\n","                ok_cnt += 1\n","                done.add(idx)\n","                time.sleep(0.1)\n","\n","            except Exception as e:\n","                tqdm.write(f\"‚ùå Failed video {idx}: {e}\")\n","                skip_cnt += 1\n","\n","        jf.flush()\n","\n","    print(f\"\\n{'='*70}\")\n","    print(f\"‚úÖ CHUNK COMPLETE - SAVED TO GOOGLE DRIVE!\")\n","    print(f\"{'='*70}\")\n","    print(f\"Successfully captioned this run: {ok_cnt} videos\")\n","    print(f\"Errors/skipped this run: {skip_cnt} videos\")\n","    print(f\"üíæ Progress saved to: {JSONL_PATH}\")\n"],"metadata":{"id":"tVLYtkvNC7go","colab":{"base_uri":"https://localhost:8080/","height":566},"executionInfo":{"status":"ok","timestamp":1763991266875,"user_tz":300,"elapsed":296035,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"0dbc6987-5774-40f8-93c4-8c242fea970d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Loading manifest and dataset...\n","Found existing progress file! Copying locally for fast read...\n"]},{"output_type":"stream","name":"stderr","text":["Loading completed entries: 1050it [00:00, 73364.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","CAPTIONING STATUS (Google Drive)\n","======================================================================\n","‚úÖ Already completed: 1050 videos\n","üìù Remaining: 21 videos\n","üéØ Total readable videos: 1071\n","\n","‚ñ∂Ô∏è  This run will process: 21 videos\n","üíæ Progress file: /content/drive/MyDrive/Deep Learning Fall 2025/Scene/motion_captions_gemini_scene.jsonl\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["Captioning (chunk of 21): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [04:54<00:00, 14.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","‚úÖ CHUNK COMPLETE - SAVED TO GOOGLE DRIVE!\n","======================================================================\n","Successfully captioned this run: 21 videos\n","Errors/skipped this run: 0 videos\n","üíæ Progress saved to: /content/drive/MyDrive/Deep Learning Fall 2025/Scene/motion_captions_gemini_scene.jsonl\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!pip install xlsxwriter"],"metadata":{"id":"VxXmPo4WvW4I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763971054949,"user_tz":300,"elapsed":5208,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"c9899479-1a9d-4e84-90c6-a7f2dd3a5135"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xlsxwriter\n","  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n","Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n","\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/175.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.2.9\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"KnSq8OrwreyO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763991275314,"user_tz":300,"elapsed":759,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"d91ed3ba-f8ba-4f7f-d90d-be7a7544b766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Reading JSONL file...\n","Saving to Excel...\n","\n","======================================================================\n","‚úÖ EXCEL EXPORT COMPLETE!\n","======================================================================\n","Total captions: 1071\n","Saved to: /content/drive/MyDrive/Deep Learning Fall 2025/Scene/scene_captions_gemini.xlsx\n","\n","üìä Preview:\n","   row_idx                                  caption_generated\n","0        0  The video features a series of short, dynamic ...\n","1        1  A young woman stands outdoors in a peaceful, w...\n","2        2  This video shows a single, dramatic scene from...\n"]}],"source":["# Cell 9: Export to Excel\n","\n","from google.colab import drive\n","import pandas as pd\n","import json\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# JSONL_PATH = \"/content/camerabench/outputs/motion_captions_gemini_motiononly_deduped.jsonl\"\n","JSONL_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/Scene/motion_captions_gemini_scene.jsonl\"\n","\n","SAVE_XLSX = \"/content/drive/MyDrive/Deep Learning Fall 2025/Scene/scene_captions_gemini.xlsx\"\n","\n","print(\"Reading JSONL file...\")\n","rows = []\n","with open(JSONL_PATH, \"r\") as f:\n","    for line in f:\n","        s = line.strip()\n","        if not s:\n","            continue\n","        try:\n","            obj = json.loads(s)\n","            rows.append({\n","                \"row_idx\": obj.get(\"row_idx\"),\n","                \"video_link\": obj.get(\"video_link\"),\n","                \"caption_generated\": obj.get(\"caption_generated\"),\n","                \"id_or_video_path\": obj.get(\"id_or_video_path\"),\n","                \"labels\": obj.get(\"labels\"),\n","                \"human_motion_caption\": obj.get(\"human_motion_caption\"),\n","            })\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è  Skipping malformed line: {e}\")\n","\n","# Create DataFrame\n","df = pd.DataFrame(rows)\n","\n","# Save to Excel\n","print(f\"Saving to Excel...\")\n","os.makedirs(os.path.dirname(SAVE_XLSX), exist_ok=True)\n","\n","with pd.ExcelWriter(SAVE_XLSX, engine=\"xlsxwriter\") as writer:\n","    df.to_excel(writer, index=False, sheet_name=\"captions\")\n","\n","    # Auto-adjust column widths\n","    worksheet = writer.sheets[\"captions\"]\n","    for i, col in enumerate(df.columns):\n","        max_len = max(df[col].astype(str).map(len).max(), len(col)) + 2\n","        worksheet.set_column(i, i, min(max_len, 50))\n","\n","print(f\"\\n{'='*70}\")\n","print(f\"‚úÖ EXCEL EXPORT COMPLETE!\")\n","print(f\"{'='*70}\")\n","print(f\"Total captions: {len(df)}\")\n","print(f\"Saved to: {SAVE_XLSX}\")\n","print(f\"\\nüìä Preview:\")\n","print(df.head(3)[[\"row_idx\", \"caption_generated\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mo4pxZFuxZAM"},"outputs":[],"source":["# --- Colab: Progress polling & peek ---\n","!wc -l /content/camerabench/outputs/motion_captions_qwen_gif.jsonl || echo \"No JSONL yet.\"\n","\n","# Print first 3 non-empty, well-formed lines\n","import json\n","path = \"/content/camerabench/outputs/motion_captions_qwen_gif.jsonl\"\n","try:\n","    with open(path, \"r\") as f:\n","        shown = 0\n","        for line in f:\n","            s = line.strip()\n","            if not s:\n","                continue\n","            try:\n","                obj = json.loads(s)\n","                print(json.dumps(obj, indent=2, ensure_ascii=False))\n","                shown += 1\n","                if shown >= 3:\n","                    break\n","            except Exception:\n","                continue\n","except FileNotFoundError:\n","    print(\"JSONL not found.\")"]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"SjChaiYkhe5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/camerabench_full_backup/outputs"],"metadata":{"id":"qZYbnAAuhnRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXByFdudxaPO"},"outputs":[],"source":["# --- Colab: Export to Excel (Drive) ---\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","\n","JSONL_PATH = \"/content/drive/MyDrive/camerabench_full_backup/outputs/motion_captions_qwen_gif.jsonl\"\n","# JSONL_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_qwen_gif.jsonl\"\n","SAVE_XLSX = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_qwen_2.xlsx\"\n","\n","rows = []\n","with open(JSONL_PATH, \"r\") as f:\n","    for line in f:\n","        s = line.strip()\n","        if not s:\n","            continue\n","        try:\n","            obj = json.loads(s)\n","            rows.append({\n","                \"video_link\": obj.get(\"video_link\"),\n","                \"caption_generated\": obj.get(\"caption_generated\"),\n","                \"id_or_video_path\": obj.get(\"id_or_video_path\"),\n","            })\n","        except Exception:\n","            # skip malformed lines\n","            pass\n","\n","df = pd.DataFrame(rows, columns=[\"video_link\", \"caption_generated\", \"id_or_video_path\"])\n","os.makedirs(os.path.dirname(SAVE_XLSX), exist_ok=True)\n","with pd.ExcelWriter(SAVE_XLSX, engine=\"xlsxwriter\") as writer:\n","    df.to_excel(writer, index=False, sheet_name=\"captions\")\n","\n","print(\"Saved Excel to:\", SAVE_XLSX)\n","print(df.head(3))"]},{"cell_type":"markdown","source":["# Calculate BERT SCORE"],"metadata":{"id":"SqqD8mEnfyy3"}},{"cell_type":"code","source":["!pip install bert-score pandas\n"],"metadata":{"id":"0MjOcEk0fY7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Cell 10: Compute and Save BERTScore (from motion_captions_qwen.xlsx) ---\n","!pip install -q bert-score pandas openpyxl\n","\n","import pandas as pd\n","from bert_score import score\n","\n","# Paths\n","EXCEL_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_qwen.xlsx\"\n","SAVE_PATH  = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_bertscore.xlsx\"\n","\n","# --- Load Excel ---\n","df = pd.read_excel(EXCEL_PATH)\n","print(f\"‚úÖ Loaded {len(df)} rows from {EXCEL_PATH}\")\n","\n","# --- Extract captions for scoring ---\n","preds = df[\"caption_generated\"].astype(str).tolist()\n","refs  = df[\"human_motion_caption\"].astype(str).tolist()\n","\n","# --- Compute BERTScore (default: roberta-large) ---\n","P, R, F1 = score(preds, refs, lang=\"en\")\n","\n","# --- Add scores as new columns ---\n","df[\"bertscore_precision\"] = P.tolist()\n","df[\"bertscore_recall\"]    = R.tolist()\n","df[\"bertscore_f1\"]        = F1.tolist()\n","\n","# --- Compute and display averages ---\n","precision_mean = P.mean().item()\n","recall_mean = R.mean().item()\n","f1_mean = F1.mean().item()\n","\n","print(\"\\n================ BERTScore (Gemini Captions) ================\")\n","print(f\"Precision: {precision_mean:.4f}\")\n","print(f\"Recall:    {recall_mean:.4f}\")\n","print(f\"F1:        {f1_mean:.4f}\")\n","print(\"============================================================\")\n","\n","# --- Match collaborator‚Äôs column order ---\n","cols_order = [\n","    \"video_link\",\n","    \"caption_generated\",\n","    \"human_motion_caption\",\n","    \"bertscore_precision\",\n","    \"bertscore_recall\",\n","    \"bertscore_f1\",\n","    \"labels\",\n","    \"id_or_video_path\",\n","]\n","\n","# Fill missing columns with blanks if necessary\n","for col in cols_order:\n","    if col not in df.columns:\n","        df[col] = \"\"\n","\n","df = df[cols_order]\n","\n","# --- Save to Excel ---\n","df.to_excel(SAVE_PATH, index=False)\n","print(f\"üíæ Saved detailed BERTScore results to {SAVE_PATH}\")\n"],"metadata":{"id":"EbsQtY2li0gP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd\n","from bert_score import score\n","import os\n","\n","# Paths\n","EXCEL_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_qwen.xlsx\"\n","SAVE_PATH  = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_bertscore.xlsx\"\n","\n","# --- Load Excel ---\n","df = pd.read_excel(EXCEL_PATH)\n","print(f\"‚úÖ Loaded {len(df)} rows from {EXCEL_PATH}\")\n","\n","# --- Extract caption pairs ---\n","preds = df[\"caption_generated\"].astype(str).tolist()\n","refs  = df[\"human_motion_caption\"].astype(str).tolist()\n","\n","# --- Compute BERTScore (default roberta-large) ---\n","P, R, F1 = score(preds, refs, lang=\"en\", verbose=True)\n","\n","# --- Add BERTScore columns ---\n","df[\"bertscore_precision\"] = [round(p.item(), 10) for p in P]\n","df[\"bertscore_recall\"]    = [round(r.item(), 10) for r in R]\n","df[\"bertscore_f1\"]        = [round(f.item(), 10) for f in F1]\n","\n","# --- Compute averages ---\n","precision_mean = P.mean().item()\n","recall_mean = R.mean().item()\n","f1_mean = F1.mean().item()\n","\n","print(\"\\n================ BERTScore (Gemini Captions) ================\")\n","print(f\"Precision: {precision_mean:.4f}\")\n","print(f\"Recall:    {recall_mean:.4f}\")\n","print(f\"F1:        {f1_mean:.4f}\")\n","print(\"============================================================\")\n","\n","# --- Order columns like collaborator ---\n","cols_order = [\n","    \"row_idx\",\n","    \"video_link\",\n","    \"caption_generated\",\n","    \"human_motion_caption\",\n","    \"bertscore_precision\",\n","    \"bertscore_recall\",\n","    \"bertscore_f1\",\n","    \"labels\",\n","    \"id_or_video_path\",\n","]\n","for col in cols_order:\n","    if col not in df.columns:\n","        df[col] = \"\"\n","\n","df = df[cols_order]\n","\n","# --- Add average summary row ---\n","summary = {\n","    \"row_idx\": \"AVERAGE\",\n","    \"bertscore_precision\": round(precision_mean, 4),\n","    \"bertscore_recall\": round(recall_mean, 4),\n","    \"bertscore_f1\": round(f1_mean, 4),\n","}\n","df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)\n"],"metadata":{"id":"mBLOdr2ykkzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","!pip install -q xlsxwriter\n","\n","# --- Save formatted Excel ---\n","os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n","with pd.ExcelWriter(SAVE_PATH, engine=\"xlsxwriter\") as writer:\n","    df.to_excel(writer, index=False, sheet_name=\"captions\")\n","\n","    worksheet = writer.sheets[\"captions\"]\n","\n","    # Auto-adjust column widths\n","    for i, col in enumerate(df.columns):\n","        max_len = max(df[col].astype(str).map(len).max(), len(col)) + 2\n","        worksheet.set_column(i, i, min(max_len, 70))\n","\n","print(f\"\\n‚úÖ Saved full BERTScore results to:\\n{SAVE_PATH}\")"],"metadata":{"id":"oeMRtyksk6yE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","FILE_PATH = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_bertscore.xlsx\"\n","SAVE_FIXED = \"/content/drive/MyDrive/Deep Learning Fall 2025/motion_captions_gemini_bertscore_fixed.xlsx\"\n","\n","# --- Load file ---\n","df = pd.read_excel(FILE_PATH)\n","print(f\"‚úÖ Loaded {len(df)} rows\")\n","\n","# --- Step 1: Force numeric conversion ---\n","df[\"row_idx\"] = pd.to_numeric(df[\"row_idx\"], errors=\"coerce\")\n","\n","# Step 2: Identify any non-numeric or NaN row_idx rows (e.g., \"AVERAGE\" or blanks)\n","non_numeric = df[df[\"row_idx\"].isna()]\n","if not non_numeric.empty:\n","    print(f\"‚ö†Ô∏è Found {len(non_numeric)} non-numeric row_idx rows (keeping them at end):\")\n","    print(non_numeric.head(3))\n","else:\n","    print(\"‚úÖ All row_idx values are numeric.\")\n","\n","# --- Step 3: Sort numerically, keeping any NaN or text rows last ---\n","df_sorted = df.sort_values(by=\"row_idx\", ascending=True, na_position=\"last\").reset_index(drop=True)\n","\n","# --- Step 4: Verify continuity and check duplicates ---\n","duplicates = df_sorted[df_sorted[\"row_idx\"].duplicated(keep=False)]\n","if not duplicates.empty:\n","    print(f\"‚ö†Ô∏è Warning: Found {len(duplicates)} duplicate row_idx entries.\")\n","    print(duplicates[[\"row_idx\", \"id_or_video_path\"]])\n","else:\n","    print(\"‚úÖ No duplicate row_idx values found.\")\n","\n","# Check if 699 is in correct position\n","if (df_sorted[\"row_idx\"] == 699).any():\n","    idx_699 = df_sorted.index[df_sorted[\"row_idx\"] == 699][0]\n","    print(f\"‚úÖ Row 699 now appears at DataFrame index position: {idx_699}\")\n","else:\n","    print(\"‚ö†Ô∏è Row 699 not found! Check for typos or missing data.\")\n","\n","# --- Step 5: Save clean file ---\n","with pd.ExcelWriter(SAVE_FIXED, engine=\"xlsxwriter\") as writer:\n","    df_sorted.to_excel(writer, index=False, sheet_name=\"captions\")\n","    worksheet = writer.sheets[\"captions\"]\n","    for i, col in enumerate(df_sorted.columns):\n","        max_len = max(df_sorted[col].astype(str).map(len).max(), len(col)) + 2\n","        worksheet.set_column(i, i, min(max_len, 70))\n","\n","print(f\"\\nüíæ Saved clean, sorted file to:\\n{SAVE_FIXED}\")\n"],"metadata":{"id":"1JmJaDA1nJCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","ds = load_dataset(\"syCen/CameraBench\", split=\"test\")\n"],"metadata":{"id":"pwlhonea8qVO","executionInfo":{"status":"ok","timestamp":1763972394958,"user_tz":300,"elapsed":1121,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["video_bytes = ds[0]\n"],"metadata":{"id":"kA04MU508rzi","executionInfo":{"status":"ok","timestamp":1763972412610,"user_tz":300,"elapsed":27,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["video_bytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MJBWQGk8wHq","executionInfo":{"status":"ok","timestamp":1763972418699,"user_tz":300,"elapsed":19,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}},"outputId":"aec432f5-319a-4ab9-d277-9f41d96e5f37"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Video': 'https://huggingface.co/datasets/syCen/CameraBench/resolve/main/videos_gif/-2uIa-XMJC0.5.3.gif',\n"," 'labels': ['minimal-shaking', 'complex-motion', 'regular-speed', 'tilt-down'],\n"," 'caption': 'The camera smoothly trucks slightly to the left, then quickly tilts downward before moving backward to follow the skateboarder, maintaining minimal shaking throughout.',\n"," 'path': 'videos/-2uIa-XMJC0.5.3.mp4'}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["!mkdir -p \"/content/drive/MyDrive/camerabench\"\n","\n","!cp -r /content/camerabench/videos_gif_mp4 \\\n","      \"/content/drive/MyDrive/camerabench/videos_mp4\"\n","\n","!cp /content/camerabench/outputs/gif2mp4_manifest.json \\\n","      \"/content/drive/MyDrive/camerabench/manifest.json\"\n"],"metadata":{"id":"qkwMNMvw9gp-","executionInfo":{"status":"ok","timestamp":1763972678309,"user_tz":300,"elapsed":62147,"user":{"displayName":"Stephen Dong","userId":"04348147209048929483"}}},"execution_count":44,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1RHttpZDojwSJ3V3qaIWqPvp4-jyU3zII","timestamp":1762560403446}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7c4ada1e421c4c84b83f248802bff7c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fb51345f5f64dc7bead1d0b2cc36598","IPY_MODEL_d3f4966049d64d7a905e0cb7451e1b3c","IPY_MODEL_9fdb679e9c484e0996e09f6386cfb9d6"],"layout":"IPY_MODEL_35ad0208b523411dad135fcdae542edf"}},"3fb51345f5f64dc7bead1d0b2cc36598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37e0225c262d49f29854e64eb049a32a","placeholder":"‚Äã","style":"IPY_MODEL_42e340adff754d9cac54782f2a6eb64d","value":"README.md:‚Äá"}},"d3f4966049d64d7a905e0cb7451e1b3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5900828a578245cf8478eb25a741f48d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a90f914b399b4632a41f656c12701197","value":1}},"9fdb679e9c484e0996e09f6386cfb9d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17fdaf5b0e9142b780d5958ee96a342e","placeholder":"‚Äã","style":"IPY_MODEL_db6182df546747d889baf637514975cf","value":"‚Äá4.49k/?‚Äá[00:00&lt;00:00,‚Äá403kB/s]"}},"35ad0208b523411dad135fcdae542edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37e0225c262d49f29854e64eb049a32a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e340adff754d9cac54782f2a6eb64d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5900828a578245cf8478eb25a741f48d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a90f914b399b4632a41f656c12701197":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17fdaf5b0e9142b780d5958ee96a342e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db6182df546747d889baf637514975cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98f8247980054434972fb57ba437554a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_319f757c1ac14bfa9329d2eef1633f5a","IPY_MODEL_13c19467da4c44399800200fb6ca328b","IPY_MODEL_70174eaab16d41f5874bbc74f8a5a97c"],"layout":"IPY_MODEL_cbdd83f9ba9f44d48cd68ab8dbb72230"}},"319f757c1ac14bfa9329d2eef1633f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_757190464a554e61b6874ded4b684227","placeholder":"‚Äã","style":"IPY_MODEL_606ed4ef49b74c33badfb39beef81a23","value":"test.jsonl:‚Äá"}},"13c19467da4c44399800200fb6ca328b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7373bde21c64975ac413e82e0dbf3d5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c7dbd022b7f42dbb9099700194e2a72","value":1}},"70174eaab16d41f5874bbc74f8a5a97c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5903cb88278244cdb4d7d863c7c43dae","placeholder":"‚Äã","style":"IPY_MODEL_6ca6183e41f14be9a657666d2b78d736","value":"‚Äá404k/?‚Äá[00:00&lt;00:00,‚Äá43.8MB/s]"}},"cbdd83f9ba9f44d48cd68ab8dbb72230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"757190464a554e61b6874ded4b684227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"606ed4ef49b74c33badfb39beef81a23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7373bde21c64975ac413e82e0dbf3d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1c7dbd022b7f42dbb9099700194e2a72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5903cb88278244cdb4d7d863c7c43dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ca6183e41f14be9a657666d2b78d736":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f1daeded20e4b219bd7088d57735412":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_593fdc39199a43dc8c74b819e687d4b5","IPY_MODEL_beb91707559b472a82812da5026318e5","IPY_MODEL_98b20c950f5147298ea60615642d3d3e"],"layout":"IPY_MODEL_90a38217e5fc4d138bac0bb94be5fd9f"}},"593fdc39199a43dc8c74b819e687d4b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41f44a827b95469c9493d3203cf524c9","placeholder":"‚Äã","style":"IPY_MODEL_e447cefb8d5540d7b8fbba01dba93d5e","value":"Generating‚Äátest‚Äásplit:‚Äá100%"}},"beb91707559b472a82812da5026318e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c00265b729fd45c38dfecb90078f4ac5","max":1071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a33ae91c8514d79baa4e45778d62db0","value":1071}},"98b20c950f5147298ea60615642d3d3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fca1618a07f4bd0bd1bbb99edf11674","placeholder":"‚Äã","style":"IPY_MODEL_43f0110654884c5cb4f85510cf13057c","value":"‚Äá1071/1071‚Äá[00:00&lt;00:00,‚Äá32412.87‚Äáexamples/s]"}},"90a38217e5fc4d138bac0bb94be5fd9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f44a827b95469c9493d3203cf524c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e447cefb8d5540d7b8fbba01dba93d5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c00265b729fd45c38dfecb90078f4ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a33ae91c8514d79baa4e45778d62db0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fca1618a07f4bd0bd1bbb99edf11674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f0110654884c5cb4f85510cf13057c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}